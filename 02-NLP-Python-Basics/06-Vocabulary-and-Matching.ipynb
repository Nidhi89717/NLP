{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e09ec6e",
   "metadata": {},
   "source": [
    "# Vocabulary and Matching\n",
    "So far we've seen how a body of text is divided into tokens, and how individual tokens are parsed and tagged with parts of speech, dependencies and lemmas.\n",
    "\n",
    "In this section we will identify and label specific phrases that match patterns we can define ourselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56b342",
   "metadata": {},
   "source": [
    "## Rule-based Matching\n",
    "spaCy offers a rule-matching tool called `Matcher` that allows you to build a library of token patterns, then match those patterns against a Doc object to return a list of found matches. You can match on any part of the token including text and annotations, and you can add multiple patterns to the same matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bba30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a66a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e35b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6326234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd705e86",
   "metadata": {},
   "source": [
    "<font color=green>Here `matcher` is an object that pairs to the current `Vocab` object. We can add and remove specific named matchers to `matcher` as needed.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb16f5",
   "metadata": {},
   "source": [
    "### Creating patterns\n",
    "In literature, the phrase 'solar power' might appear as one word or two, with or without a hyphen. In this section we'll develop a matcher named 'SolarPower' that finds all three:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a3ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SolarPower\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "#Solar-power\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True},{'LOWER':'power'}]\n",
    "#Solar power\n",
    "pattern3 = [{'LOWER':'solar'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96a4ad",
   "metadata": {},
   "source": [
    "Let's break this down:\n",
    "* `pattern1` looks for a single token whose lowercase text reads 'solarpower'\n",
    "* `pattern2` looks for two adjacent tokens that read 'solar' and 'power' in that order\n",
    "* `pattern3` looks for three adjacent tokens, with a middle token that can be any punctuation.<font color=green>*</font>\n",
    "\n",
    "<font color=green>\\* Remember that single spaces are not tokenized, so they don't count as punctuation.</font>\n",
    "<br>Once we define our patterns, we pass them into `matcher` with the name 'SolarPower', and set *callbacks* to `None` (more on callbacks later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f4acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [pattern1,pattern2,pattern3]\n",
    "matcher.add('SolarPower',patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c2f45",
   "metadata": {},
   "source": [
    "### Applying the matcher to a Doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1e4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar Power industry continues to grow as demand \\\n",
    "for solarpower increases. Solar-power cars are gaining popularity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b3f205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27505c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8656102463236116519, 1, 3),\n",
       " (8656102463236116519, 10, 11),\n",
       " (8656102463236116519, 13, 16)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ab151",
   "metadata": {},
   "source": [
    "`matcher` returns a list of tuples. Each tuple contains an ID for the match, with start & end tokens that map to the span `doc[start:end]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49574196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 10 11 solarpower\n",
      "8656102463236116519 SolarPower 13 16 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc[start:end]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a6301e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd7bf24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solarpower SolarPower\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "#Solar.power\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e23bc721",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [pattern1,pattern2]\n",
    "matcher.add('Solarpower',pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21b64948",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'Solar--power is solarpower yay!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ab8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "founder_match = matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44007f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6544436658971563323, 0, 3), (6544436658971563323, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(founder_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afae43a",
   "metadata": {},
   "source": [
    "___\n",
    "## PhraseMatcher\n",
    "In the above section we used token patterns to perform rule-based matching. An alternative - and often more efficient - method is to match on terminology lists. In this case we use PhraseMatcher to create a Doc object from a list of phrases, and pass that into `matcher` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39bc8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2c4250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phraser = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4dbfc",
   "metadata": {},
   "source": [
    "Source: https://en.wikipedia.org/wiki/Reaganomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e0b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reaganomics.txt') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56546299",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = ['voodoo economics', 'supply-side economics', 'trickle-down economics', 'free-market economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6393713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa96b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[voodoo economics,\n",
       " supply-side economics,\n",
       " trickle-down economics,\n",
       " free-market economics]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be9aa3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(phase_patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0970ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [nlp('voodoo economics'),nlp('supply-side economics')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "927f23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "phraser.add('EconMatcher',phase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df574716",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = phraser(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1c580d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3680293220734633682, 41, 45),\n",
       " (3680293220734633682, 49, 53),\n",
       " (3680293220734633682, 54, 56),\n",
       " (3680293220734633682, 61, 65),\n",
       " (3680293220734633682, 673, 677),\n",
       " (3680293220734633682, 2987, 2991)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44fe0940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680293220734633682 EconMatcher 41 45 supply-side economics\n",
      "3680293220734633682 EconMatcher 49 53 trickle-down economics\n",
      "3680293220734633682 EconMatcher 54 56 voodoo economics\n",
      "3680293220734633682 EconMatcher 61 65 free-market economics\n",
      "3680293220734633682 EconMatcher 673 677 supply-side economics\n",
      "3680293220734633682 EconMatcher 2987 2991 trickle-down economics\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  \n",
    "    span = doc3[start:end]              \n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f57c321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680293220734633682 EconMatcher 41 45 policies are commonly associated with supply-side economics, referred to as trickle-down economics or voodoo\n",
      "3680293220734633682 EconMatcher 49 53 economics, referred to as trickle-down economics or voodoo economics by political opponents, and free-\n",
      "3680293220734633682 EconMatcher 54 56 trickle-down economics or voodoo economics by political opponents, and free-market economics by\n",
      "3680293220734633682 EconMatcher 61 65 by political opponents, and free-market economics by political advocates.\n",
      "\n",
      "The four pillars of Reagan\n",
      "3680293220734633682 EconMatcher 673 677 attracted a following from the supply-side economics movement, which formed in opposition to Keynesian demand-\n",
      "3680293220734633682 EconMatcher 2987 2991 became widely known as \"trickle-down economics\", due to the significant cuts in the upper\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  \n",
    "    span = doc3[start-5:end+10]                   \n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "146ea3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35\n"
     ]
    }
   ],
   "source": [
    "sents = [sent for sent in doc3.sents]\n",
    "\n",
    "print(sents[0].start,sents[0].end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cdeec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the same time he attracted a following from the supply-side economics movement, which formed in opposition to Keynesian demand-stimulus economics.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the sentence list until the sentence end value exceeds a match start value:\n",
    "for sent in sents:\n",
    "    if found_matches[4][1] < sent.end:  # this is the fifth match, that starts at doc3[673]\n",
    "        print(sent)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
